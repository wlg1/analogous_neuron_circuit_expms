# analogous_neuron_circuit_expms

[UNDER CONSTRUCTION]

Analogous Neural Circuit Experiments aim to find common patterns in neural network activations based on inputs with varying similarities. Why study Analogous Neural Circuit Experiments? These studies enhance Neural Network Interpretability by connecting model predictions to patterns the model uses to make its predictions. This has significant applications, which include:
<ul>
<li><b>Improving Trust in AI:</b> When AI makes important decisions, such as in medical treatment or financial investments, knowing why the AI made those predictions is crucial to ensuring that it is not using faulty reasoning to make its predictions. </li>
<li><b>Improving Model Debugging:</b> By uncovering the black box that obscures how neural networks make decisions, practitioners will have more control over debugging neural networks to do what they want. </li>
<li><b>Improving Transfer Learning:</b> By understanding which parts of a neural network perform what function, practitioners will be able to dissect neural networks to retrieve the part they need, and apply transfer learning to fine tune that part to suit their own, specific goals.</li>
</ul>

"Analogous" patterns refer to ... [cite commutative diagrams, structure preserving maps, Forbus/Gentner], as opposed to "Same" patterns using the exact same neurons...

These experiments are explained through a series of Colab notebooks that walk the reader through how the experiments were conducted. An example of a notebook demonstrating simple experiments is given below:

<a href="https://colab.research.google.com/drive/12hQolN9TLXsakkG96nYUgU30_6YL74bf#scrollTo=IAJjuRTDBnOr">TUTORIAL 1: Compare Neuron Activations Between Pairs of Images</a>

Other notebooks are listed as follows:

<a href="https://colab.research.google.com/drive/15dQyu5t3fkFBfsp5sKe0KdPiNI6G28Rm">TUTORIAL 2: Find the previous layer neurons that contributed the most to the highest class probability</a>

---

Below are 'Appendix Tutorials', which contain mostly negative results from which one can still infer information.

<a href="https://colab.research.google.com/drive/1Jcv2-E8YOt5d9F88Tx1CXIuQqZJxkqqx">APPENDIX TUTORIAL 1: Compare Neuron Activations Across Layers Between Categories of Images</a>


---

[state underlying assumptions and hypotheses to test]
