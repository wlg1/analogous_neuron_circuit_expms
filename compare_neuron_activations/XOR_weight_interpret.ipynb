{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Use a NN to model XOR\n",
        "\n",
        "Study how individual motifs work to compose into larger circuits. Just like how studying AND gate composes into larger computer circuit, or how studying cells and particles enables understanding on a macroscopic level.\n",
        "\n",
        "Not for a research paper, but for personal understanding, which will help for future research papers.\n",
        "\n",
        "XOR is a geometric motif in latent space. Do other such motifs exist? Perhaps there is an analogous mathematical calculation to describe these motifs, and that generalizes these observations of this notebook."
      ],
      "metadata": {
        "id": "NgcSEMUjxL64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import torch\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os "
      ],
      "metadata": {
        "id": "gtIFVSFiemkY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Feedforward(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Feedforward, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size  = hidden_size\n",
        "        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)  # one hidden layer\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(self.hidden_size, 1)  #output layer w/o sigmoid\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        hidden = self.fc1(x)\n",
        "        relu = self.relu(hidden)\n",
        "        output = self.fc2(relu)\n",
        "        output = self.sigmoid(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "PQEESxRaeoLZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Feedforward(2, 2)\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "WxWLSjWReokH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor(np.array([[0,0], [0,1], [1,0], [1,1]]))\n",
        "y_train = torch.FloatTensor(np.array([0,1,1,0]))"
      ],
      "metadata": {
        "id": "a4OXVdjofEiE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model training is different every time, so keep training from scratch until get one with low loss. Sometimes it may get stuck, sometimes it goes very low. This is due to initial conditions interacting with GD, as gradient descent is not random."
      ],
      "metadata": {
        "id": "V_qkpfgEsZ-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "epoch = 15000\n",
        "\n",
        "for epoch in range(epoch):\n",
        "    #sets the gradients to zero before we start backpropagation. \n",
        "    #This is a necessary step as PyTorch accumulates the gradients from the backward passes from the previous epochs.\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), y_train)\n",
        "   \n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "vEfPg8mXevcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_pred = model(x_train)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T_uh9aPgbUs",
        "outputId": "410893f2-9998-44b4-889b-4d20841efff9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0230],\n",
              "        [0.9941],\n",
              "        [0.9941],\n",
              "        [0.0230]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"state_dict_model.pt\"\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "KS4wS4VItUsw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Get activations\n"
      ],
      "metadata": {
        "id": "XhlF5lry1pIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_activations(input, layer_name, model):\n",
        "    activation = {}\n",
        "    def get_activation(name):\n",
        "        def hook(model, input, output):\n",
        "            activation[name] = output.detach()\n",
        "        return hook\n",
        "\n",
        "    for name_to_check, layer in model.named_modules():\n",
        "        if name_to_check == layer_name:\n",
        "            break\n",
        "    layer.register_forward_hook(get_activation(layer_name))\n",
        "    \n",
        "    output = model(input)\n",
        "\n",
        "    return activation.copy()  #else will return the same actvs of model"
      ],
      "metadata": {
        "id": "b0Q2cv-Gg2-b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get previous last layer name\n",
        "named_layers = dict(model.named_modules())\n",
        "layers = list(named_layers.keys())\n",
        "\n",
        "# too many branches, so just get the converged branch points\n",
        "# '' is the entire model, so disregard it\n",
        "# layers = [x for x in layers if '.' not in x and x != '']  \n",
        "layers = [x for x in layers if x != '']  \n",
        "layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsCO7p5ghn6r",
        "outputId": "face3e58-aea3-4292-f9f5-5f0e2c3d8647"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fc1', 'relu', 'fc2', 'sigmoid']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Compare different input activations\n",
        "\n",
        "Compare [0, 0] and [1, 0]"
      ],
      "metadata": {
        "id": "fe9CiE2IzobT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PcNkuzIjW_c",
        "outputId": "78eaae2d-4fdb-4c30-f78f-284b02093a95"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_1 = x_train[0]\n",
        "out = model(input_1)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtUduynfh5WV",
        "outputId": "43f284bb-4acf-4935-942e-f5afb3f6aabe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0230], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print(get_activations(input_1, layer_name, model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgWQBapQhu_2",
        "outputId": "d12bd7d0-b9ad-43f7-f532-78c1ab026930"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1': tensor([-1.8150e-05, -1.6780e-04])}\n",
            "{'relu': tensor([0., 0.])}\n",
            "{'fc2': tensor([-3.7482])}\n",
            "{'sigmoid': tensor([0.0230])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_2 = x_train[0] + torch.tensor([1,0])\n",
        "input_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B30L-rM0ZAB",
        "outputId": "c31a8770-ea4e-4784-979a-daed6fd02639"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print(get_activations(input_2, layer_name, model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7uJ3bIo2hzL",
        "outputId": "d956468e-1fc5-4842-9fa9-8b84d8f98c43"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1': tensor([-2.5164,  2.4917])}\n",
            "{'relu': tensor([0.0000, 2.4917])}\n",
            "{'fc2': tensor([5.1242])}\n",
            "{'sigmoid': tensor([0.9941])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print( '[0,0]:', get_activations(input_1, layer_name, model), '[1,0]:', get_activations(input_2, layer_name, model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaWcNLRT4faK",
        "outputId": "47c3d89f-1ce0-4231-ead6-3e456bf7e1f3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0,0]: {'fc1': tensor([-1.8150e-05, -1.6780e-04])} [1,0]: {'fc1': tensor([-2.5164,  2.4917])}\n",
            "[0,0]: {'relu': tensor([0., 0.])} [1,0]: {'relu': tensor([0.0000, 2.4917])}\n",
            "[0,0]: {'fc2': tensor([-3.7482])} [1,0]: {'fc2': tensor([5.1242])}\n",
            "[0,0]: {'sigmoid': tensor([0.0230])} [1,0]: {'sigmoid': tensor([0.9941])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    diff = get_activations(input_2, layer_name, model)[layer_name] - get_activations(input_1, layer_name, model)[layer_name]\n",
        "    print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKvQzZZojQd_",
        "outputId": "22a47041-e704-4e6f-b5a7-15f35c8ea674"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.5164,  2.4918])\n",
            "tensor([0.0000, 2.4917])\n",
            "tensor([8.8724])\n",
            "tensor([0.9711])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Why does this input change cause this difference?\n",
        "\n",
        "Why are the activations different? Let's look at how each activation is calculated, and how the change in input causes the change in activation."
      ],
      "metadata": {
        "id": "HnO3gvvxjPt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EEVG3AxlamN",
        "outputId": "ba611980-9fb4-486a-95ab-bd6977d40573"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Feedforward(\n",
              "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leeiDSBBi1hR",
        "outputId": "a777f32c-742c-4585-99bd-df53cada5446"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-2.5164,  2.5164],\n",
            "        [ 2.4918, -2.4921]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-1.8150e-05, -1.6780e-04], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[3.5254, 3.5608]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-3.7482], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prev_weights = model.fc1.weight.data\n",
        "prev_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PJMJ_Fcih8Y",
        "outputId": "7b8b8ee6-2425-4548-fe22-79818289736b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.5164,  2.5164],\n",
              "        [ 2.4918, -2.4921]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in layers:\n",
        "    if isinstance(named_layers[layer], torch.nn.Linear):\n",
        "        print(layer, named_layers[layer].state_dict()['bias'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60Kz7M-IlDVk",
        "outputId": "387d3bbe-2480-41e4-dbd4-93cd0dc24be2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc1 tensor([-1.8150e-05, -1.6780e-04])\n",
            "fc2 tensor([-3.7482])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(model.fc1.weight.data, input_1) + named_layers['fc1'].state_dict()['bias']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWGz-fnHkihG",
        "outputId": "e8ea10a1-1a4e-4b9b-da95-c422ab3d084c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.8150e-05, -1.6780e-04])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_activations(input_1, 'fc1', model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIEESnkowo66",
        "outputId": "400b47b3-0ea4-49c5-a44e-b3514fe2815c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1': tensor([-1.8150e-05, -1.6780e-04])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(model.fc1.weight.data, input_2)  + named_layers['fc1'].state_dict()['bias']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5SkMAulnMe0",
        "outputId": "7a26068a-b5d8-4768-89d0-e99cba8e5278"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.5164,  2.4917])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Break down each step of W * X + b"
      ],
      "metadata": {
        "id": "Pg8tBtwXtIk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc1.weight.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8FRJFM2tKdY",
        "outputId": "4b87546f-510a-4bdf-b5d9-3d2bc9ac9fcd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.5164,  2.5164],\n",
              "        [ 2.4918, -2.4921]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTuxxnF1tgoF",
        "outputId": "05e69997-83ce-458e-e75e-3d64be3e719f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get:\n",
        "\n",
        "[$w_{11} * x_1$ $w_{12} * x_2$]\n",
        "\n",
        "[$w_{21} * x_1$ $w_{22} * x_2$]"
      ],
      "metadata": {
        "id": "kB-xU87Qw8jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WX_hadamard = torch.multiply(model.fc1.weight.data, input_2)\n",
        "WX_hadamard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0ZAOwGAsA2e",
        "outputId": "0cba4c08-e719-4add-b837-9d2905ecf38b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.5164,  0.0000],\n",
              "        [ 2.4918, -0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WX:\n",
        "\n",
        "[$w_{11}$ $w_{12}$]\n",
        "\n",
        "[$w_{21}$ $w_{22}$]\n",
        "\n",
        "w11 * (1) - w12 * 0 = w11\n",
        "\n",
        "w21 * (1) + w22 * 0 = w21\n",
        "\n",
        "Thus, when you change the input from [0, 0] to [1, 0], you are changing WX from [0, 0] to [w11, w21]. And we know that [1, 0] is supposed to be 1.\n",
        "\n",
        "Likewise, [0, 1] as input gets:\n",
        "\n",
        "[$w_{11} * x_1$ $w_{12} * x_2$] = [$w_{12}$]\n",
        "\n",
        "[$w_{21} * x_1$ $w_{22} * x_2$] = [$w_{22}$]\n",
        "\n",
        "But we also need [1, 1] to be 0, so it's not as simple as \"make it so the neuron outputs are bigger\". "
      ],
      "metadata": {
        "id": "MFSOGb3QtoW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_3 = torch.FloatTensor(np.array([1,1]))\n",
        "input_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOC5MW_xvZgd",
        "outputId": "4221378b-b4f7-460f-ff45-4bf916b1f0e3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print(get_activations(input_3, layer_name, model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pl5CPs0vnTY",
        "outputId": "bf524489-b478-41d3-cbfe-ec02cc5a3a12"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1': tensor([-2.6733e-05, -3.7474e-04])}\n",
            "{'relu': tensor([0., 0.])}\n",
            "{'fc2': tensor([-3.7482])}\n",
            "{'sigmoid': tensor([0.0230])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    diff = get_activations(input_3, layer_name, model)[layer_name] - get_activations(input_1, layer_name, model)[layer_name]\n",
        "    print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAYgAl6ev_aw",
        "outputId": "dd1e86e7-fd74-466d-d14b-b50b1bb6959d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-8.5831e-06, -2.0695e-04])\n",
            "tensor([0., 0.])\n",
            "tensor([0.])\n",
            "tensor([0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[0, 0] and [1, 1] have the SAME neuron outputs after fc1. Let's look at the weights of fc1 again to see why that's the case."
      ],
      "metadata": {
        "id": "8jhHweq9wRsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc1.weight.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-HCBi1EwZBr",
        "outputId": "a139232c-4545-4a8c-d7b7-dac43e55d91f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.5164,  2.5164],\n",
              "        [ 2.4918, -2.4921]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WX_hadamard = torch.multiply(model.fc1.weight.data, input_3)\n",
        "WX_hadamard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8_u4oI3wnuv",
        "outputId": "1b95cf83-9ff7-488e-aded-fad60c80ee41"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.5164,  2.5164],\n",
              "        [ 2.4918, -2.4921]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first element of WX is 0 or close to 0.\n",
        "\n",
        "The second element is also close to 0.\n",
        "\n",
        "So the weights were learned to make sure w11 - w12 was close to 0, as ReLU would turn that into 0.\n",
        "\n",
        "Then in fc2 (output node), the bias is negative so that sigmoid makes it less than 0. \n",
        "\n",
        "But for [0,1] and [1,0], w11 - w12 is nonzero. The more different they are, the more one will be expressed than the other. But when x1 and x2 are close, because w11 and w12 are also close, the first output of fc1 (w11*x1 + w12*x2) is close to 0.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WqmNyaNTwi04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why hidden layer for two elements?\n",
        "\n",
        "Matrix multiplication is unit conversion. Here, the first element of WX for fc1 is measuring how close x1 and x2 are. But the second element is doing the same thing. Is it even necessary?\n",
        "\n",
        "Yes, it's necessary for [0, 1] and [1, 0]. Notice **because w11 or w12 must be negative, and the other must be positive** (WLOG say w11 is positive), then [1, 0] will return w11, a positive (a non-zero after ReLU) for the first element, but [0, 1] will return w12, a negative (a zero after ReLU). \n",
        "\n",
        "Even without ReLU, we want to output POSITIVE 1, not negative 1. So this cannot work.\n",
        "\n",
        "Thus, we need the second row (second element of fc1) so that [0, 1] can return a positive (a non-zero after ReLU)."
      ],
      "metadata": {
        "id": "BqRA-AOTq_DY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Gradual input modification \n",
        "\n",
        "Now slightly modify the input and see what happens to each layer!\n",
        "\n",
        "Try different modification levels. As you gradually change it, how do the weights change?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Use:\n",
        "torch.tensor([0.0, 0.0]) instead of torch.tensor([0, 0])\n",
        "\n",
        "https://stackoverflow.com/questions/60440292/runtimeerror-expected-scalar-type-long-but-found-float"
      ],
      "metadata": {
        "id": "aARB9Xwa0V8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name = 'fc1'\n",
        "# step_incr = [round(x * 0.1, 1) for x in range(0, 10)]\n",
        "old_input = torch.tensor([0.0, 0.0])\n",
        "new_input = torch.tensor([0.0, 0.0])\n",
        "# for i in step_incr:\n",
        "for i in range(0, 10):\n",
        "    old_input = new_input.clone()\n",
        "    new_input = old_input + torch.tensor([0.1, 0])\n",
        "    # new_input = torch.tensor([i, 0])\n",
        "    print(round(0.1 * i, 1))\n",
        "    diff = get_activations(new_input, layer_name, model)[layer_name] - get_activations(old_input, layer_name, model)[layer_name]\n",
        "    print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIFRwlqQ0aNL",
        "outputId": "f77f2241-e3aa-406b-e2fe-785571c1005e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "tensor([-0.2516,  0.2492])\n",
            "0.1\n",
            "tensor([-0.2516,  0.2492])\n",
            "0.2\n",
            "tensor([-0.2516,  0.2492])\n",
            "0.3\n",
            "tensor([-0.2516,  0.2492])\n",
            "0.4\n",
            "tensor([-0.2516,  0.2492])\n",
            "0.5\n",
            "tensor([-0.2516,  0.2492])\n",
            "0.6\n",
            "tensor([-0.2516,  0.2492])\n",
            "0.7\n",
            "tensor([-0.2516,  0.2492])\n",
            "0.8\n",
            "tensor([-0.2516,  0.2492])\n",
            "0.9\n",
            "tensor([-0.2516,  0.2492])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's the same increment every time, since WX+b is linear.\n",
        "\n",
        "Now instead of comparing with previous, compare it with original, [0,0]"
      ],
      "metadata": {
        "id": "GH8CmR_h6rUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name = 'fc1'\n",
        "# old_input = torch.tensor([0.0, 0.0])\n",
        "new_input = torch.tensor([0.0, 0.0])\n",
        "print('orig actvs: ', get_activations(torch.tensor([0.0, 0.0]), layer_name, model)[layer_name] )\n",
        "for i in range(1, 10):\n",
        "    old_input = new_input.clone()\n",
        "    new_input = old_input + torch.tensor([0.1, 0])\n",
        "    print([round(0.1 * i, 1), 0])\n",
        "    actv_new = get_activations(new_input, layer_name, model)[layer_name]\n",
        "    # actv_orig = get_activations(torch.tensor([0.0, 0.0]), layer_name, model)[layer_name]\n",
        "    # diff = actv_new - actv_orig\n",
        "    # print(torch.round(diff, decimals=1))\n",
        "    print(actv_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIKtVXtp6q05",
        "outputId": "11442568-9aa9-4b46-a4c4-85c7678a244a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orig actvs:  tensor([-1.8150e-05, -1.6780e-04])\n",
            "[0.1, 0]\n",
            "tensor([-0.2517,  0.2490])\n",
            "[0.2, 0]\n",
            "tensor([-0.5033,  0.4982])\n",
            "[0.3, 0]\n",
            "tensor([-0.7549,  0.7474])\n",
            "[0.4, 0]\n",
            "tensor([-1.0066,  0.9966])\n",
            "[0.5, 0]\n",
            "tensor([-1.2582,  1.2458])\n",
            "[0.6, 0]\n",
            "tensor([-1.5099,  1.4949])\n",
            "[0.7, 0]\n",
            "tensor([-1.7615,  1.7441])\n",
            "[0.8, 0]\n",
            "tensor([-2.0131,  1.9933])\n",
            "[0.9, 0]\n",
            "tensor([-2.2648,  2.2425])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Review the actual activation diffs b/w [0, 0] and [1, 0]"
      ],
      "metadata": {
        "id": "korHeVOGBFik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print( '[0,0]:', get_activations(input_1, layer_name, model), '[1,0]:', get_activations(input_2, layer_name, model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPhA83AZBJpB",
        "outputId": "2463c735-6feb-4d0d-a061-18664e491cb0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0,0]: {'fc1': tensor([-1.8150e-05, -1.6780e-04])} [1,0]: {'fc1': tensor([-2.5164,  2.4917])}\n",
            "[0,0]: {'relu': tensor([0., 0.])} [1,0]: {'relu': tensor([0.0000, 2.4917])}\n",
            "[0,0]: {'fc2': tensor([-3.7482])} [1,0]: {'fc2': tensor([5.1242])}\n",
            "[0,0]: {'sigmoid': tensor([0.0230])} [1,0]: {'sigmoid': tensor([0.9941])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before, we saw that going from [0, 0] to [1, 0] makes WX go from around [0, 0] to [w11, w21]. For fc1_1, we see a decrease from ~0 to w11 as x1 gets larger. Similarly, fc1_2 is closer to w21 as x gets larger. \n",
        "\n",
        "Clearly due to ReLU, w11 is not needed in [x1, 0] (st x1 > 0) because w11 is negative and thus will always be turned to 0. It only cares about increasing fc1_2 from 0 to w21. But for [0, 1], [fc1_1, fc1_2] = [w12, w22] where w12 > 0 and w22 < 0, so in that case, the first element fc1_1 increases. The [0,1] and [1,0] have to ensure that at least one output of fc1's (WX + b) is positive.\n",
        "\n",
        "If [fc1_1 and fc1_2] are close to 0, since the bias is negative, the relu will make them [0,0]. \n",
        "\n",
        "(Keep in mind this model was only overfitted on 4 data pts, so it doesn't do well for data pts in b/w.)"
      ],
      "metadata": {
        "id": "8HDWZsmw65rN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Let's gradually change along the diagonal from [0,0] to [1,1]"
      ],
      "metadata": {
        "id": "-Qa-h8WWAWEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name = 'fc1'\n",
        "old_input = torch.tensor([0.0, 0.0])\n",
        "new_input = torch.tensor([0.0, 0.0])\n",
        "for i in range(1, 10):\n",
        "    old_input = new_input.clone()\n",
        "    new_input = old_input + torch.tensor([0.1, 0.1])\n",
        "    print([round(0.1 * i, 1), round(0.1 * i, 1)])\n",
        "    actv_new = get_activations(new_input, layer_name, model)[layer_name]\n",
        "    actv_orig = get_activations(torch.tensor([0.0, 0.0]), layer_name, model)[layer_name]\n",
        "    diff = actv_new - actv_orig\n",
        "    print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSgfv6EIAbW1",
        "outputId": "88655a8e-080e-4ef9-b31f-a3493147110c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.1, 0.1]\n",
            "tensor([-8.3447e-07, -2.0698e-05])\n",
            "[0.2, 0.2]\n",
            "tensor([-1.6689e-06, -4.1395e-05])\n",
            "[0.3, 0.3]\n",
            "tensor([-2.5630e-06, -6.2108e-05])\n",
            "[0.4, 0.4]\n",
            "tensor([-3.3379e-06, -8.2791e-05])\n",
            "[0.5, 0.5]\n",
            "tensor([-4.2915e-06, -1.0347e-04])\n",
            "[0.6, 0.6]\n",
            "tensor([-5.1260e-06, -1.2422e-04])\n",
            "[0.7, 0.7]\n",
            "tensor([-6.0797e-06, -1.4484e-04])\n",
            "[0.8, 0.8]\n",
            "tensor([-6.9141e-06, -1.6558e-04])\n",
            "[0.9, 0.9]\n",
            "tensor([-7.6294e-06, -1.8620e-04])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Along this diagonal, [fc1_1 and fc1_2] always stay negative and close to 0, unlike going from [0, 0] to [1, 0], where fc1_1 decreases (getting closer to w11, which is -2.5) and fc1_2 increases (getting closer to w12, which is 2.5).\n",
        "\n",
        "This is because fc1_1 = w11 + w12, and w11 ~= -w12, so whenever the coefficients x1 and x2 are close in value, so will x1 * w11 and x2 * w12. "
      ],
      "metadata": {
        "id": "nj4UIgmhAgWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Conditions to allow NN to model XOR: (one possible state)\n",
        "\n",
        "- fc1_1: the weights were learned to make sure w1 - w2 was close to 0 (ie. w11 ~= -w12)\n",
        "- fc1_2: if w11 is negative, w21 should be positive, and vv. if w12 is negative, w22 should be positive, and vv.\n",
        "- fc2's bias should be negative to ensure WX after fc2, if 0, will make it neg, thus making sigmoid make WX+b be close to 0\n",
        "\n",
        "Any NN with the architecture above whose weights satisfy these conditions will model XOR.\n",
        "\n",
        "Thus, we can possibly analogously match NNs satisfying these same conditions by their motifs. \n",
        "\n",
        "Put in these constraints then use a constraint solver to find the weights needed.\n",
        "\n",
        "**Additionally**, we may be able to find 'training patterns' which allow the NN training algorithms to figure out which motifs it needs in a 'meaningful' way, matching regions to 'meaning' that corresponds to the data, instead of simply using gradient descent and other optimization methods. We combine 'training patterns' with other methods such as GD and neuro-evolution."
      ],
      "metadata": {
        "id": "e3YhHgKt480T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Change of basis, human-like interpretation (approx.):\n",
        "\n",
        "For fc1, the first row of WX measures how similar $x_1$ and $x_2$ are. The second row does the same, but is neg when the first row is pos, and vv."
      ],
      "metadata": {
        "id": "lm-jq8-97m0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Now these NN motifs are how weights are related to one another. For instance, w11 ~= -w12. Any sub-network satisfying these constraints is \"that motif\". Finding these motifs across a large NN means finding patterns that satisfy each condition. Each condition is stricter, making a more specific and larger pattern query, so adding more conditions means less matches.\n",
        "\n",
        "These are not 'exact' patterns, but analogous, since weights are RELATIVE to one another. For instance, w11 > w12, not requiring w11 to exactly have some value (though it may).\n",
        "\n",
        "Note that even the network topology may not be the same. You can have a path, such that it's not that one neuron that's a neighbor needs to be related to another in such a way, but that another neuron somewhere down the path has that relation.\n",
        "\n",
        "Finding these conditions does not need human interpretation- these general motif conditions may be inferred by an algorithm (learned or not) by taking in multiple NNs with the same role. This 'meta learning' will take in NNs as training data and find the common patterns they all have.\n",
        "\n",
        "This meta NN will be applied to networks. Then you can apply it to a NN to find subgraph patterns that it says 'yes' on. It scans the larger NN to find potential areas, growing larger from those sub-areas (this may be a DRL problem). "
      ],
      "metadata": {
        "id": "TssTqwl6Bk71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Try training it again and look at the weights\n",
        "\n",
        "For multiple training instances, does it do this every time? There may be multiple ways for an ANN circuit to calculate XOR."
      ],
      "metadata": {
        "id": "KXcdKzM5G21l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Feedforward(2, 2)\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model_2.parameters(), lr = 0.01)\n",
        "\n",
        "# if you continue training, usually will get stuck?\n",
        "\n",
        "x_train = torch.FloatTensor(np.array([[0,0], [0,1], [1,0], [1,1]]))\n",
        "y_train = torch.FloatTensor(np.array([0,1,1,0]))"
      ],
      "metadata": {
        "id": "6MiU8IfCIzg3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.train()\n",
        "epoch = 15000\n",
        "\n",
        "for epoch in range(epoch):\n",
        "    #sets the gradients to zero before we start backpropagation. \n",
        "    #This is a necessary step as PyTorch accumulates the gradients from the backward passes from the previous epochs.\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model_2(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), y_train)\n",
        "   \n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "9MiNuwcMIzg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.eval()\n",
        "y_pred = model_2(x_train)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SvMcQJkJUsF",
        "outputId": "5e563fd5-924e-4aa0-8d8f-74a6545037a0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0125],\n",
              "        [0.9578],\n",
              "        [0.9578],\n",
              "        [0.0156]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"state_dict_model_2.pt\"\n",
        "torch.save(model_2.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "8Mn2RZDBF68P"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model_2.parameters():\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0IjYJn8I5aP",
        "outputId": "206e636e-29cd-4cd6-a996-cde3303e6151"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 2.0555,  2.0556],\n",
            "        [-2.1004, -2.1004]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-2.0558,  2.1001], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-3.5337, -3.5672]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([3.1211], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time is strange. Now, w11 = w12, and w21 = w22. But w11 and w12 are positive, while w21 and w22 are negative. So this is a second set of conditions?\n"
      ],
      "metadata": {
        "id": "BxWaj5viJ9-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print(get_activations(input_1, layer_name, model_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gKxV_USHDBh",
        "outputId": "987189be-2bbd-48e0-ded6-a5cbc0ed0a44"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1': tensor([-2.0558,  2.1001])}\n",
            "{'relu': tensor([0.0000, 2.1001])}\n",
            "{'fc2': tensor([-4.3703])}\n",
            "{'sigmoid': tensor([0.0125])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the activations after fc1 are just the bias."
      ],
      "metadata": {
        "id": "leOXlT7FIIMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print(get_activations(input_2, layer_name, model_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPg4CPjIHLO_",
        "outputId": "01cdf6fc-0431-4544-f8e6-0e834708441d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1': tensor([-0.0003, -0.0003])}\n",
            "{'relu': tensor([0., 0.])}\n",
            "{'fc2': tensor([3.1211])}\n",
            "{'sigmoid': tensor([0.9578])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print(get_activations(input_3, layer_name, model_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxwGaCLgHHAG",
        "outputId": "727960bb-82ff-42b2-be95-3e18e0750221"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1': tensor([ 2.0553, -2.1007])}\n",
            "{'relu': tensor([2.0553, 0.0000])}\n",
            "{'fc2': tensor([-4.1417])}\n",
            "{'sigmoid': tensor([0.0156])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compared to [0, 0], the fc activations have opp signs. "
      ],
      "metadata": {
        "id": "rJmv1GqqJMAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_4 = torch.FloatTensor(np.array([0,1]))\n",
        "for layer_name in layers:\n",
        "    print(get_activations(input_4, layer_name, model_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5D36LHKJgOf",
        "outputId": "123a275f-900f-475f-927e-781f78404d3a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1': tensor([-0.0002, -0.0003])}\n",
            "{'relu': tensor([0., 0.])}\n",
            "{'fc2': tensor([3.1211])}\n",
            "{'sigmoid': tensor([0.9578])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see for both [0, 1] and [1, 0], now the key is that the fc1 are close to 0. This pattern means the second class, regardless of being 0 or 1, is 'zeroed out'. Essentially, a reset, to allow second layer to do something new. Once 'zeroed out', the bias 3.1211 is able to be added. It's positive, meaning sigmoid will turn it close to 1."
      ],
      "metadata": {
        "id": "-kmNIUbzJvQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the reason why [0, 0] and [1, 1] differ from the 'opposing x1 and x2' is because after the (first and only) ReLU, there is one element that is positive. Since the fc2 weights are both negative and sufficiently big enough, this means fc2 will ALWAYS give a negative because w*x means negative * positive = negative, and they're big enough to always ensure adding the bias won't make wx+b be >0. In contrast, the [1, 0] and [0, 1] would 'zero out' and ignore fc2's weights, depending only on the positive bias."
      ],
      "metadata": {
        "id": "NfMBtoLyHhlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are strategies that can be used throughout the NN. They are not packaged into 'human concept' units like 'cat eye' or 'cat paw', but they are still patterns that one can interpret in the ANN circuit. Perhaps these patterns exist throughout ANNs."
      ],
      "metadata": {
        "id": "A4bMpIC_MlAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Manually modify weights to try to create XOR, based on conditions\n",
        "\n",
        "We can try manually inserting weights that meet those conditions generalized from model 1 (based on reasons why model 1 works)."
      ],
      "metadata": {
        "id": "9YNbOZ8wl9wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = Feedforward(2, 2)"
      ],
      "metadata": {
        "id": "G4kBfkjlKMTb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.fc1.weight.data = torch.FloatTensor(np.array([[1, -1], [-1,1]]))"
      ],
      "metadata": {
        "id": "FdelxK_pm7mJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.fc1.weight.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1hOiWf-nis7",
        "outputId": "db60cbbf-62c4-4d23-cb38-a81b9f7953a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., -1.],\n",
              "        [-1.,  1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.fc2.bias.data = torch.FloatTensor(np.array([-1]))"
      ],
      "metadata": {
        "id": "sLwg9UfXm5K4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.eval()\n",
        "y_pred = model_3(x_train)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVKpaQ32nnwZ",
        "outputId": "6572b7a8-3262-4cc9-b33f-9a9a79bcefac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3509],\n",
              "        [0.2839],\n",
              "        [0.5076],\n",
              "        [0.3509]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's not accurate. Analyze what happened in the activations."
      ],
      "metadata": {
        "id": "Ox4ZLFFYnuew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print(get_activations(input_1, layer_name))"
      ],
      "metadata": {
        "id": "16A8UVF0o9Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Try using single layer perceptron\n",
        "\n",
        "Matrix multiplication is unit conversion. Here, the first element of WX for fc1 is measuring how close x1 and x2 are. But the second element is doing the same thing. Is it even necessary?"
      ],
      "metadata": {
        "id": "z_m3ALeD2qS7"
      }
    }
  ]
}