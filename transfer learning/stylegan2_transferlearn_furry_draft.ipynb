{"cells":[{"cell_type":"markdown","source":["# Loading pretrained model"],"metadata":{"id":"OoXtREIdXVtz"}},{"cell_type":"markdown","metadata":{"id":"liKaTLyUo0Nk"},"source":["https://www.reddit.com/r/MediaSynthesis/comments/gum6f1/tfdne_edit_furry_faces_inbrowser_google_colab/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ixs37iA-Mxf2"},"outputs":[],"source":["# !git clone https://github.com/shawwn/stylegan2 -b estimator /content/stylegan2"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49164,"status":"ok","timestamp":1651171525204,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"pXcjXwwhzJOW","outputId":"8c4f5c7b-7fb0-4524-85e1-9cd930dd3d3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-28 18:44:36--  https://thisfursonadoesnotexist.com/model/network-e621-r-512-3194880.pkl\n","Resolving thisfursonadoesnotexist.com (thisfursonadoesnotexist.com)... 172.67.159.181, 104.21.14.150, 2606:4700:3034::ac43:9fb5, ...\n","Connecting to thisfursonadoesnotexist.com (thisfursonadoesnotexist.com)|172.67.159.181|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 364035409 (347M) [application/octet-stream]\n","Saving to: ‘/content/network-e621.pkl’\n","\n","/content/network-e6 100%[===================>] 347.17M  7.21MB/s    in 48s     \n","\n","2022-04-28 18:45:25 (7.25 MB/s) - ‘/content/network-e621.pkl’ saved [364035409/364035409]\n","\n"]}],"source":["import gdown\n","!wget  -O /content/network-e621.pkl https://thisfursonadoesnotexist.com/model/network-e621-r-512-3194880.pkl\n","# !wget  -O /content/directions.zip https://thisfursonadoesnotexist.com/directions.zip"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":246,"status":"ok","timestamp":1651171657759,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"w_diRM7Fn1Pa","outputId":"5a39c0a2-1bf6-490d-e252-1db2265150d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/stylegan2\n"]}],"source":["%tensorflow_version 1.x\n","%cd /content/stylegan2"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":241,"status":"ok","timestamp":1651171709211,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"Pt4kvzEM39oI"},"outputs":[],"source":["import os\n","import pickle\n","import numpy as np\n","import PIL.Image\n","import dnnlib\n","import dnnlib.tflib as tflib\n","import scipy\n","import tensorflow as tf\n","# import tflex"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"8coaz5KZeFum","executionInfo":{"status":"ok","timestamp":1651171682287,"user_tz":240,"elapsed":152,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["if 'COLAB_TPU_ADDR' in os.environ:\n","    os.environ['TPU_NAME'] = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","    os.environ['NOISY'] = '1'"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38500,"status":"ok","timestamp":1651171751825,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"Mg9DrxVNJ8am","outputId":"d0c4cc97-bef9-4d45-cc5e-c2169c2e488c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n"]}],"source":["tflib.init_tf()\n","sess = tf.get_default_session()\n","sess.list_devices()\n","# cores = tflex.get_cores()\n","# tflex.set_override_cores(cores)\n","_G, _D, Gs = pickle.load(open(\"/content/network-e621.pkl\", \"rb\"))\n","\n","\n","# _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.\n","# _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.\n","# Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zh5l7AqyI_7u"},"outputs":[],"source":[" def generate_image_from_w(w, truncation_psi):\n","    with tflex.device('/gpu:0'):\n","        #_G, _D, Gs = pickle.load(open(\"/content/network-e621.pkl\", \"rb\"))\n","        noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n","        Gs_kwargs = dnnlib.EasyDict()\n","        Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","        Gs_kwargs.randomize_noise = False\n","        if truncation_psi is not None:\n","            Gs_kwargs.truncation_psi = truncation_psi\n","        synthesis_kwargs = dict(output_transform=Gs_kwargs.output_transform, truncation_psi=truncation_psi, minibatch_size=1)\n","        images = Gs.components.synthesis.run(w, randomize_noise=False, **synthesis_kwargs)\n","        #PIL.Image.fromarray(images[0], 'RGB').save('seed%04d.png' % seed)\n","        display(PIL.Image.fromarray(images[0], 'RGB'))"]},{"cell_type":"markdown","source":["\n","\n","---\n","# Loading data into tfrecords\n","\n"],"metadata":{"id":"Gh65PxRBXO40"}},{"cell_type":"markdown","metadata":{"id":"0zLm_smSZJLo"},"source":["\n","\n","---\n","\n","**Loading tf records**\n","\n","https://www.kaggle.com/datasets/brendanartley/anime-faces-tfrecords\n","\n","First upload kaggle.json. May have to pause a min after uploading before running dataset download code."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_PZNnfoZKYt"},"outputs":[],"source":["# %%capture\n","# ! pip install kaggle\n","# ! mkdir ~/.kaggle\n","# ! cp kaggle.json ~/.kaggle/\n","# ! chmod 600 ~/.kaggle/kaggle.json\n","# ! kaggle datasets download brendanartley/anime-faces-tfrecords\n","# ! unzip anime-faces-tfrecords.zip -d ./dataset"]},{"cell_type":"markdown","metadata":{"id":"BREPhbEKGkBR"},"source":["\n","\n","---\n","\n","**Loading low-res faces then upscaling**\n","\n","\n","https://www.kaggle.com/datasets/splcher/animefacedataset/code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h09l-cTsA8LC"},"outputs":[],"source":["# %%capture\n","# ! pip install kaggle\n","# ! mkdir ~/.kaggle\n","# ! cp kaggle.json ~/.kaggle/\n","# ! chmod 600 ~/.kaggle/kaggle.json\n","# ! kaggle datasets download splcher/animefacedataset\n","# ! unzip animefacedataset.zip "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gb0mRvrwCzV3"},"outputs":[],"source":["import os \n","import numpy as np\n","import PIL.Image\n","\n","origin_dir = './images'\n","image_names = [files for root, dirs, files in os.walk(origin_dir)][0]\n","for index, image_name in enumerate(image_names):\n","    image_path = os.path.join(origin_dir, image_name)\n","    img = np.asarray(PIL.Image.open(image_path))\n","    width, height = PIL.Image.open(image_path).size\n","    print(width, height)\n","    # img = img.reshape(1, 3, 512, 512)"]},{"cell_type":"markdown","metadata":{"id":"SleLiHQcDbyG"},"source":["We see all images are different sizes. We need to upscale them, then reshape them, else they cannot be transformed into tfrecord."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2M76qFwNeo4y"},"outputs":[],"source":["!cat /usr/local/cuda/version.txt\n","!wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_9.0.176-1_amd64.deb\n","!sudo dpkg -i cuda-repo-ubuntu1604_9.0.176-1_amd64.deb\n","!apt-get install libvulkan-dev\n","!apt-get update\n","\n","!%cd /content/\n","!git clone https://github.com/nihui/waifu2x-ncnn-vulkan.git\n","!cd waifu2x-ncnn-vulkan/\n","!git submodule update --init --recursive\n","!wget https://github.com/nihui/waifu2x-ncnn-vulkan/releases/download/20200606/waifu2x-ncnn-vulkan-20200606-linux.zip\n","!unzip waifu2x-ncnn-vulkan-20200606-linux.zip\n","%cd waifu2x-ncnn-vulkan-20200606-linux\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":366,"status":"ok","timestamp":1650946534424,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"ONHKknp7D1XY","outputId":"67e16276-91cb-443d-8349-142e8fe6ee64"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘2x’: File exists\n","./waifu2x-ncnn-vulkan: error while loading shared libraries: libvulkan.so.1: cannot open shared object file: No such file or directory\n"]}],"source":["# upload all files first ->\n","%mkdir 2x\n","# !for img in *.??g; do ./waifu2x-ncnn-vulkan -i $img -o 2x/${img%.*}_2x.png; done\n","!for img in /content/images; do ./waifu2x-ncnn-vulkan -i $img -o 2x/${img%.*}_2x.png; done\n","\n","\n","# copying in gdrive\n","#!gsutil -m cp -r hand_tuned_larger/ '/content/drive/My Drive/twist_moe/hand_tuned_larger_2x/'"]},{"cell_type":"markdown","metadata":{"id":"9X0mFcSfGmGr"},"source":["\n","\n","---\n","\n","**Loading a subset of high-res faces**\n","\n","https://www.kaggle.com/datasets/subinium/highresolution-anime-face-dataset-512x512"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"9TLs-sEqGmyA","executionInfo":{"status":"ok","timestamp":1651169916975,"user_tz":240,"elapsed":103623,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}}},"outputs":[],"source":["%%capture\n","! pip install kaggle\n","! mkdir ~/.kaggle\n","! cp kaggle.json ~/.kaggle/\n","! chmod 600 ~/.kaggle/kaggle.json\n","! kaggle datasets download subinium/highresolution-anime-face-dataset-512x512\n","# ! unzip highresolution-anime-face-dataset-512x512.zip "]},{"cell_type":"markdown","source":["Unzip only 5000 files from zip\n","\n","https://stackoverflow.com/questions/22243031/unzip-only-limited-number-of-files-in-linux"],"metadata":{"id":"8_BU5CzUbNP1"}},{"cell_type":"code","source":["!unzip -Z1 highresolution-anime-face-dataset-512x512.zip | head -5000 | sed 's| |\\\\ |g' | xargs unzip highresolution-anime-face-dataset-512x512.zip"],"metadata":{"id":"ijgWDlXYYwk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install numpy==1.19.5\n","\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","\n","# Download the code\n","!git clone https://github.com/ZKTKZ/stylegan2.git\n","# %cd stylegan2\n","# !nvcc test_nvcc.cu -o test_nvcc -run\n","!nvcc /content/stylegan2/test_nvcc.cu -o /content/stylegan2/test_nvcc -run\n","\n","print('Tensorflow version: {}'.format(tf.__version__) )\n","!nvidia-smi -L\n","print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))\n","\n","!pip install tensorboard"],"metadata":{"id":"-AlDIGKsbovh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342217,"status":"ok","timestamp":1651171173957,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"dK28KWzYkWyb","outputId":"e4624200-a062-4bc3-9d45-ec4df150f03f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading images from \"./portraits\"\n","detected 5000 images ...\n","Creating dataset \"./training_data\"\n","Adding the images to tfrecords ...\n","0 / 5000\r/content/stylegan2/dataset_tool.py:154: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n","  bytes_list=tf.train.BytesList(value=[quant.tostring()])\n","Added 5000 images.\n"]}],"source":["# convert images to tfrecord\n","\n","!python /content/stylegan2/dataset_tool.py create_from_images ./training_data ./portraits "]},{"cell_type":"markdown","metadata":{"id":"exxDPsWJ_wP5"},"source":["https://www.tensorflow.org/tutorials/load_data/tfrecord\n","\n","\n","\n","---\n","\n","**Download high-res directly from drive**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1651001526417,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"3wcvgGelXCdd","outputId":"43081d75-2400-47e2-f1d0-14809e1baf4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading 1xJyTl4Svz-kd8ysgttGRRjYh-vNmUhuX into /content/data/1xJyTl4Svz-kd8ysgttGRRjYh-vNmUhuX... Done.\n"]}],"source":["# import gdown\n","# from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","# model_id = '' #get from 'copy link', after /d/ and before /view\n","# network_pkl = '/content/models/model_%s.pkl' % model_id#(hashlib.md5(model_id.encode()).hexdigest())\n","# gdd.download_file_from_google_drive(file_id=model_id, dest_path=network_pkl)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17914,"status":"ok","timestamp":1651001739672,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"w453ESRdXvoK","outputId":"1be5d0ef-36d9-4db0-f648-fa452642013f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/drive')  #brings google drive files to be accessible under /content/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZUqPqB2XLD6"},"outputs":[],"source":["!unzip -u \"/content/drive/My Drive/high_res_anime_faces.zip\" -d ./data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WdrMSDAdYkej"},"outputs":[],"source":["# cannot run this on .zip\n","!python /content/stylegan2/dataset_tool.py create_from_images \\\n","    \"/content/drive/My Drive/high_res_anime_faces_tfrecords\" \\\n","    \"/content/data\""]},{"cell_type":"markdown","source":["\n","\n","---\n","# Training\n"],"metadata":{"id":"BLGjC1pYXh_9"}},{"cell_type":"markdown","metadata":{"id":"2OuZ4XYaach3"},"source":["\n","\n","https://colab.research.google.com/github/ZKTKZ/thdne/blob/master/StyleGAN2_Tazik_25GB_RAM.ipynb#scrollTo=vmeWpLdZdhq2"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":464632,"status":"ok","timestamp":1651172276780,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"},"user_tz":240},"id":"41wVnrihpz_G","outputId":"9878e861-7385-4035-dd2c-c858988dd4bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Local submit - run_dir: /content/drive/My Drive/twist_moe/results/00002-stylegan2-training_data-1gpu-config-f\n","dnnlib: Running training.training_loop.training_loop() on localhost...\n","Streaming data using training.dataset.TFRecordDataset...\n","Dataset shape = [3, 512, 512]\n","Dynamic range = [0, 255]\n","Label size    = 0\n","2022-04-28 18:50:33.488143: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 94371840 exceeds 10% of system memory.\n","Loading networks from \"../network-e621.pkl\"...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n","\n","G                             Params    OutputShape         WeightShape     \n","---                           ---       ---                 ---             \n","latents_in                    -         (?, 512)            -               \n","labels_in                     -         (?, 0)              -               \n","lod                           -         ()                  -               \n","dlatent_avg                   -         (512,)              -               \n","G_mapping/latents_in          -         (?, 512)            -               \n","G_mapping/labels_in           -         (?, 0)              -               \n","G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n","G_mapping/Broadcast           -         (?, 16, 512)        -               \n","G_mapping/dlatents_out        -         (?, 16, 512)        -               \n","Truncation/Lerp               -         (?, 16, 512)        -               \n","G_synthesis/dlatents_in       -         (?, 16, 512)        -               \n","G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n","G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n","G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n","G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n","G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n","G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n","G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n","G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n","G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n","G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n","G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n","G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n","G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n","G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n","G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n","G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n","G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n","G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n","G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n","G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n","G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n","G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n","G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n","G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n","G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n","G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n","G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n","G_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64) \n","G_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)  \n","G_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -               \n","G_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)   \n","G_synthesis/images_out        -         (?, 3, 512, 512)    -               \n","G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n","G_synthesis/noise1            -         (1, 1, 8, 8)        -               \n","G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n","G_synthesis/noise3            -         (1, 1, 16, 16)      -               \n","G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n","G_synthesis/noise5            -         (1, 1, 32, 32)      -               \n","G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n","G_synthesis/noise7            -         (1, 1, 64, 64)      -               \n","G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n","G_synthesis/noise9            -         (1, 1, 128, 128)    -               \n","G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n","G_synthesis/noise11           -         (1, 1, 256, 256)    -               \n","G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n","G_synthesis/noise13           -         (1, 1, 512, 512)    -               \n","G_synthesis/noise14           -         (1, 1, 512, 512)    -               \n","images_out                    -         (?, 3, 512, 512)    -               \n","---                           ---       ---                 ---             \n","Total                         30276583                                      \n","\n","\n","D                    Params    OutputShape       WeightShape     \n","---                  ---       ---               ---             \n","images_in            -         (?, 3, 512, 512)  -               \n","labels_in            -         (?, 0)            -               \n","512x512/FromRGB      256       (64,)             (1, 1, 3, 64)   \n","512x512/Conv0        36928     (64,)             (3, 3, 64, 64)  \n","512x512/Conv1_down   73856     (128,)            (3, 3, 64, 128) \n","512x512/Skip         8192      (1, 1, 64, 128)   (1, 1, 64, 128) \n","256x256/Conv0        147584    (128,)            (3, 3, 128, 128)\n","256x256/Conv1_down   295168    (256,)            (3, 3, 128, 256)\n","256x256/Skip         32768     (1, 1, 128, 256)  (1, 1, 128, 256)\n","128x128/Conv0        590080    (256,)            (3, 3, 256, 256)\n","128x128/Conv1_down   1180160   (512,)            (3, 3, 256, 512)\n","128x128/Skip         131072    (1, 1, 256, 512)  (1, 1, 256, 512)\n","64x64/Conv0          2359808   (512,)            (3, 3, 512, 512)\n","64x64/Conv1_down     2359808   (512,)            (3, 3, 512, 512)\n","64x64/Skip           262144    (1, 1, 512, 512)  (1, 1, 512, 512)\n","32x32/Conv0          2359808   (512,)            (3, 3, 512, 512)\n","32x32/Conv1_down     2359808   (512,)            (3, 3, 512, 512)\n","32x32/Skip           262144    (1, 1, 512, 512)  (1, 1, 512, 512)\n","16x16/Conv0          2359808   (512,)            (3, 3, 512, 512)\n","16x16/Conv1_down     2359808   (512,)            (3, 3, 512, 512)\n","16x16/Skip           262144    (1, 1, 512, 512)  (1, 1, 512, 512)\n","8x8/Conv0            2359808   (512,)            (3, 3, 512, 512)\n","8x8/Conv1_down       2359808   (512,)            (3, 3, 512, 512)\n","8x8/Skip             262144    (1, 1, 512, 512)  (1, 1, 512, 512)\n","4x4/MinibatchStddev  -         (?, 513, 4, 4)    -               \n","4x4/Conv             2364416   (512,)            (3, 3, 513, 512)\n","4x4/Dense0           4194816   (512,)            (8192, 512)     \n","Output               513       (1,)              (512, 1)        \n","scores_out           -         (?, 1)            -               \n","---                  ---       ---               ---             \n","Total                28982849                                    \n","\n","Building TensorFlow graph...\n","Initializing logs...\n","Training for 10000 kimg...\n","\n","tick 0     kimg 0.0      lod 0.00  minibatch 4    time 37s          sec/tick 37.4    sec/kimg 2334.50 maintenance 0.0    gpumem 6.4\n","Downloading http://d36zk2xti64re0.cloudfront.net/stylegan1/networks/metrics/inception_v3_features.pkl ... done\n","^C\n"]}],"source":["!python /content/stylegan2/run_training.py --num-gpus=1 --data-dir=/content/ --config=config-f --dataset=training_data \\\n","--total-kimg=10000 --result-dir=\"/content/drive/My Drive/twist_moe/results/\" --resume-pkl='../network-e621.pkl'\n"]},{"cell_type":"code","source":["# 00002-stylegan2-training_data-1gpu-config-f\n","# network-snapshot-000000\n","!python /content/stylegan2/run_generator.py generate-images --seeds=0-100 --truncation-psi=0.7 \\\n","--network='/content/drive/My Drive/twist_moe/results/00002-stylegan2-training_data-1gpu-config-f/network-snapshot-000000.pkl'\n","#%cp -av /content/stylegan2/results/00000-generate-images /content/drive/'My Drive'/twist_moe/seeds-1.0\n"],"metadata":{"id":"9Rwm8Poem7tQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gXzkpzBqnGBK"},"source":["import os\n","import pickle\n","import numpy as np\n","import PIL.Image\n","import dnnlib\n","import dnnlib.tflib as tflib\n","import scipy\n","import math\n","import moviepy.editor\n","from numpy import linalg\n","\n","\n","def main():\n","    tflib.init_tf()\n","    _G, _D, Gs = pickle.load(open(\"/content/drive/My Drive/twist_moe/results/00002-stylegan2-training_data-1gpu-config-f/network-snapshot-000000.pkl\", \"rb\"))\n","\n","    rnd = np.random\n","    latents_a = rnd.randn(1, Gs.input_shape[1])\n","    latents_b = rnd.randn(1, Gs.input_shape[1])\n","    latents_c = rnd.randn(1, Gs.input_shape[1])\n","\n","    def circ_generator(latents_interpolate):\n","        radius = 40.0\n","\n","        latents_axis_x = (latents_a - latents_b).flatten() / linalg.norm(latents_a - latents_b)\n","        latents_axis_y = (latents_a - latents_c).flatten() / linalg.norm(latents_a - latents_c)\n","\n","        latents_x = math.sin(math.pi * 2.0 * latents_interpolate) * radius\n","        latents_y = math.cos(math.pi * 2.0 * latents_interpolate) * radius\n","\n","        latents = latents_a + latents_x * latents_axis_x + latents_y * latents_axis_y\n","        return latents\n","\n","    def mse(x, y):\n","        return (np.square(x - y)).mean()\n","\n","    def generate_from_generator_adaptive(gen_func):\n","        max_step = 1.0\n","        current_pos = 0.0\n","\n","        change_min = 10.0\n","        change_max = 11.0\n","\n","        fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","\n","        current_latent = gen_func(current_pos)\n","        current_image = Gs.run(current_latent, None, truncation_psi=0.7, randomize_noise=False, output_transform=fmt)[0]\n","        array_list = []\n","\n","        video_length = 1.0\n","        while(current_pos < video_length):\n","            array_list.append(current_image)\n","\n","            lower = current_pos\n","            upper = current_pos + max_step\n","            current_pos = (upper + lower) / 2.0\n","\n","            current_latent = gen_func(current_pos)\n","            current_image = images = Gs.run(current_latent, None, truncation_psi=0.7, randomize_noise=False, output_transform=fmt)[0]\n","            current_mse = mse(array_list[-1], current_image)\n","\n","            while current_mse < change_min or current_mse > change_max:\n","                if current_mse < change_min:\n","                    lower = current_pos\n","                    current_pos = (upper + lower) / 2.0\n","\n","                if current_mse > change_max:\n","                    upper = current_pos\n","                    current_pos = (upper + lower) / 2.0\n","\n","\n","                current_latent = gen_func(current_pos)\n","                current_image = images = Gs.run(current_latent, None, truncation_psi=0.7, randomize_noise=False, output_transform=fmt)[0]\n","                current_mse = mse(array_list[-1], current_image)\n","            print(current_pos, current_mse)\n","        return array_list\n","\n","    frames = generate_from_generator_adaptive(circ_generator)\n","    frames = moviepy.editor.ImageSequenceClip(frames, fps=30)\n","\n","    # Generate video.\n","    mp4_file = 'circular.mp4'\n","    mp4_codec = 'libx264'\n","    mp4_bitrate = '3M'\n","    mp4_fps = 20\n","\n","    frames.write_videofile(mp4_file, fps=mp4_fps, codec=mp4_codec, bitrate=mp4_bitrate)\n","\n","if __name__ == \"__main__\":\n","    main()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-HTjbmIDseN","colab":{"base_uri":"https://localhost:8080/","height":845},"executionInfo":{"status":"ok","timestamp":1651175312474,"user_tz":240,"elapsed":6386,"user":{"displayName":"Michael Lan","userId":"13558259605338023275"}},"outputId":"7261f999-3f01-4fc4-d849-47e602c60d02"},"source":["#https://stackoverflow.com/a/57378660/8773953\n","!pip install -U kora\n","from kora.drive import upload_public\n","url = upload_public('/content/stylegan2/circular.mp4')\n","\n","from IPython.display import HTML\n","HTML(f\"\"\"<video src={url} width=500 controls/>\"\"\")"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kora in /usr/local/lib/python3.7/dist-packages (0.9.19)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n","Requirement already satisfied: fastcore in /usr/local/lib/python3.7/dist-packages (from kora) (1.4.2)\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.1.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (57.4.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (3.0.8)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->kora) (0.7.0)\n"]},{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<video src=https://drive.google.com/uc?id=145TYgRwlRz5Om3SCMXUBd8EsAteBhBJF width=500 controls/>"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["!zip -r /content/anime_faces_furry_pretr.zip /content/drive/My\\ Drive/twist_moe"],"metadata":{"id":"4hAHozsuss-b"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["OoXtREIdXVtz"],"name":"stylegan2_transferlearn_furry_draft.ipynb","provenance":[],"authorship_tag":"ABX9TyNtWT0zMi8ZCMdMxRNtY+f2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}