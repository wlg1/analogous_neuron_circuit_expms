{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"map_patches_wHighestSharedNeurons.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wHVbRqznMfdw","colab":{"base_uri":"https://localhost:8080/","height":501},"executionInfo":{"status":"ok","timestamp":1646501922697,"user_tz":300,"elapsed":25571,"user":{"displayName":"Michael Lan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13558259605338023275"}},"outputId":"0068e5c8-1010-4bf6-e4dc-09f5218ee764"},"source":["!pip install numpy==1.19.5\n","!pip install --quiet lucid==0.2.3\n","\n","%tensorflow_version 1.x  #required after tf 2.0 released\n","import numpy as np\n","import tensorflow as tf\n","\n","import lucid.modelzoo.vision_models as models\n","from lucid.misc.io import show\n","import lucid.optvis.objectives as objectives\n","import lucid.optvis.param as param\n","import lucid.optvis.render as render\n","import lucid.optvis.transform as transform\n","import operator\n","import pdb\n","\n","'''\n","https://github.com/tensorflow/lucid/blob/master/lucid/modelzoo/vision_models.py\n","https://github.com/tensorflow/lucid/blob/master/lucid/modelzoo/other_models/InceptionV1.py\n","'''\n","\n","googlenet = models.InceptionV1()\n","googlenet.load_graphdef()\n","\n","# googlenet.model_path\n","\n","# models.InceptionV1.layers\n","# models.InceptionV1().layers"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy==1.19.5\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[K     |████████████████████████████████| 14.8 MB 8.4 MB/s \n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.5\n","    Uninstalling numpy-1.21.5:\n","      Successfully uninstalled numpy-1.21.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed numpy-1.19.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |████████                        | 10 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 30 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40 kB 3.2 MB/s \n","\u001b[?25h  Building wheel for lucid (setup.py) ... \u001b[?25l\u001b[?25hdone\n","`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x  #required after tf 2.0 released`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n"]}]},{"cell_type":"code","metadata":{"id":"HIYWiou_UCdc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646502198268,"user_tz":300,"elapsed":455,"user":{"displayName":"Michael Lan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13558259605338023275"}},"outputId":"e73dc693-f2f6-4932-9dc7-8f58a4c17205"},"source":["# Dissect how each var in googlenet_semantic_dict() works\n","\n","from lucid.misc.io import show, load\n","from lucid.misc.io.showing import _image_url\n","\n","def googlenet_semantic_dict(layer, img_url):\n","    img = load(img_url)\n","    \n","    # Compute the activations\n","    with tf.Graph().as_default(), tf.Session():\n","        t_input = tf.placeholder(tf.float32, [224, 224, 3]) #empty tensor of fixed size\n","        T = render.import_model(googlenet, t_input, t_input)\n","        print(T(layer))\n","        acts = T(layer).eval({t_input: img})[0]  #[0] b/c it's the only item in a list\n","        print(acts.shape)\n","        #print(acts[:,:,0].shape)\n","        #print(acts[:,:,0].size)  #activation values of semantic dict for 0th neuron of layer\n","        # ggg = [[{\"n\": n, \"v\": float(act_vec[n])} for n in np.argsort(-act_vec)[:4]] for act_vec in acts[0,:,:]]\n","        # print(len(ggg[0]))\n","        # print(ggg[0])\n","        #print(len([[[{\"n\": n, \"v\": float(act_vec[n])} for n in np.argsort(-act_vec)[:4]] for act_vec in act_slice] for act_slice in acts]))\n","        #print([[[{\"n\": n, \"v\": float(act_vec[n])} for n in np.argsort(-act_vec)[:4]] for act_vec in act_slice] for act_slice in acts])\n","                   \n","# #     vals = acts[:,:,0].flatten()\n","# #     top_neurons_of_cell = vals.argsort()[-3:][::-1]\n","# #     print(top_neurons_of_cell)\n","\n","#         top_neurons_of_cell = []\n","#         for dt in ggg[0]:\n","#           top_neurons_of_cell.append(list(dt.values())[0])\n","    \n","#     for i in top_neurons_of_cell:\n","#       obj = objectives.channel(\"mixed4d\", i)\n","#       print('channel '+str(i))\n","#       render.render_vis(googlenet, obj)\n","\n","# googlenet_semantic_dict(\"mixed4d\", \"https://storage.googleapis.com/lucid-static/building-blocks/examples/dog_cat.png\")\n","# googlenet_semantic_dict(\"mixed4d\", \"https://png.pngtree.com/png-clipart/20190604/original/pngtree-dog-pet-golden-retriever-png-image_820349.jpg\")\n","googlenet_semantic_dict(\"mixed4d\", 'dog2.jpg')"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor(\"import/mixed4d:0\", shape=(1, ?, ?, 528), dtype=float32)\n","[[[[  0.          0.          4.735308  ...   0.          0.\n","     67.1486   ]\n","   [  0.          0.         28.506151  ...   0.          0.\n","     73.85073  ]\n","   [  6.3043647   0.         15.023551  ...   0.          0.\n","     56.155212 ]\n","   ...\n","   [  0.          0.          0.        ...   0.          0.\n","     63.10116  ]\n","   [  0.          0.          0.        ...   0.          0.\n","     56.932    ]\n","   [  0.          0.          0.        ...   0.          0.\n","     45.951    ]]\n","\n","  [[  0.          0.         18.063503  ...   0.          0.\n","     84.20397  ]\n","   [  0.          0.         40.747154  ...   0.          0.\n","     78.634865 ]\n","   [  0.          0.         25.654572  ...   0.          0.\n","     69.32244  ]\n","   ...\n","   [  0.          0.          5.548671  ...   0.          0.\n","     79.05948  ]\n","   [  0.          0.          0.        ...   0.          0.\n","     76.29701  ]\n","   [  0.          0.          0.        ...   0.          0.\n","     59.09699  ]]\n","\n","  [[  0.          0.         13.9000635 ...   0.          0.\n","     72.60537  ]\n","   [  0.          0.         20.498795  ...   0.          0.\n","     76.45696  ]\n","   [  0.          0.          0.        ...   0.          0.\n","     96.121895 ]\n","   ...\n","   [  0.          0.          0.        ...   0.          0.\n","     95.670044 ]\n","   [  0.          0.          0.        ...   0.          0.\n","     78.5019   ]\n","   [  0.          0.          0.        ...   0.          0.\n","     58.99241  ]]\n","\n","  ...\n","\n","  [[  0.          0.          0.        ...   0.          0.\n","     94.312386 ]\n","   [  0.          0.          0.        ...   0.          0.\n","    132.80772  ]\n","   [  0.          0.         10.177323  ...   0.          0.\n","    149.46275  ]\n","   ...\n","   [  0.          0.          0.        ...   0.          0.\n","    152.2057   ]\n","   [  0.          0.          0.        ...   0.          0.\n","    201.6121   ]\n","   [  0.          6.764293    0.        ...   0.          0.\n","    200.00275  ]]\n","\n","  [[  0.          0.          0.        ...   0.          0.\n","     79.15219  ]\n","   [  0.          0.         11.291208  ...   0.          0.\n","    104.803795 ]\n","   [  0.          0.         18.204798  ...   0.          0.\n","    127.60241  ]\n","   ...\n","   [  0.          0.          0.        ...   0.          0.\n","    146.44493  ]\n","   [  0.          0.          0.        ...   0.          0.\n","    190.02155  ]\n","   [  0.          1.8482308   0.        ...   0.          0.\n","    195.03821  ]]\n","\n","  [[  0.          0.          0.        ...   0.          0.\n","     42.480846 ]\n","   [  0.          0.          0.        ...   0.          0.\n","     67.096756 ]\n","   [  0.          0.          6.827185  ...   0.          0.\n","     89.923325 ]\n","   ...\n","   [  0.          0.          2.603238  ...   0.          0.\n","    140.70062  ]\n","   [  0.          0.          0.        ...   0.          0.\n","    183.16971  ]\n","   [  0.          0.          0.        ...   0.          0.\n","    192.36736  ]]]]\n","(14, 14, 528)\n"]}]},{"cell_type":"code","metadata":{"id":"b51Xkwb2zxXf","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1646501956117,"user_tz":300,"elapsed":4315,"user":{"displayName":"Michael Lan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13558259605338023275"}},"outputId":"832d2bd5-d580-4f5f-820d-98052ff3c4d0"},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-c91f54f2-02ac-460f-ab40-0fe63615622b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c91f54f2-02ac-460f-ab40-0fe63615622b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving dog2.jpg to dog2.jpg\n"]}]},{"cell_type":"code","metadata":{"id":"xaPFpVVsa1UY"},"source":["from lucid.misc.io import show, load\n","from lucid.misc.io.showing import _image_url\n","\n","def output_top_neurons(layer, img_url, num_output):\n","    #num_output : top N neurons to output\n","\n","    img = load(img_url)\n","    img = np.resize(img,(224,224,3))\n","    \n","    # Compute the activations\n","    with tf.Graph().as_default(), tf.Session():\n","        t_input = tf.placeholder(tf.float32, [224, 224, 3]) #empty tensor of fixed size\n","        T = render.import_model(googlenet, t_input, t_input)\n","        acts = T(layer).eval({t_input: img})[0]\n","\n","        top_actv = [[[{\"n\": n, \"v\": float(act_vec[n])} for n in np.argsort(-act_vec)[:num_output]] \\\n","                     for act_vec in act_slice] for act_slice in acts]\n","        flat_list = [item for sublist in top_actv for item in sublist]\n","    \n","    top_neurons = []  #a list of a list of top N neurons (not their actv vals) for each of 196 patches\n","    for i in range(196):\n","      top_neurons_in_patch = []\n","      for dt in flat_list[i]:\n","          top_neurons_in_patch.append(list(dt.values())[0])\n","      top_neurons_in_patch.sort()\n","      top_neurons.append(top_neurons_in_patch)\n","    return top_neurons\n","  \n","# exhaustively compare every pair of patches\n","def map_semantic_dict(img1_neurons, img2_neurons):\n","  output_dict = {}\n","  for i, lst1 in enumerate(img1_neurons): #i: a patch in img1\n","    for j, lst2 in enumerate(img2_neurons):\n","      common_elem = set(lst1) - (set(lst1) - set(lst2))  #neurons in both patches\n","      if i in output_dict:\n","        prev_best = set(lst1) - (set(lst1) - set(img2_neurons[output_dict[i]]))\n","        if len(common_elem) > len(prev_best):  #this patch j has more matches with patch i than prev patch\n","          output_dict[i] = j  #map patch i to patch j \n","      else:\n","        output_dict[i] = j  #if same or less number of common neurons, retain first match\n","  return output_dict\n","\n","dog1_url = \"https://i.natgeofe.com/n/4f5aaece-3300-41a4-b2a8-ed2708a0a27c/domestic-dog_thumb_4x3.jpg\"\n","\n","top_neurons_img1 = output_top_neurons(\"mixed4d\", dog1_url, 4)\n","top_neurons_img2 = output_top_neurons(\"mixed4d\", 'dog2.jpg', 4)\n","top_neurons_img3 = output_top_neurons(\"mixed4d\", 'dog3.jpg', 4)\n","\n","mappings = map_semantic_dict(top_neurons_img1, top_neurons_img2)  #b/w patches in the 2 images\n","mappings_2 = map_semantic_dict(top_neurons_img1, top_neurons_img3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nL2Oyam5sRck"},"source":["# Get feature viz for the top 4 neurons that activate the most at the nose patch\n","\n","for i in top_neurons_img1[90]:  #nose\n","  obj = objectives.channel(\"mixed4d\", i)\n","  print('channel '+str(i))\n","  render.render_vis(googlenet, obj)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iapmFdZgW8Gg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646433983711,"user_tz":300,"elapsed":518,"user":{"displayName":"Michael Lan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13558259605338023275"}},"outputId":"5fc53981-2cfd-46e3-9d5e-881818f5d3a7"},"source":["# Mappings maps each patch in image1 to a patch in image2 w/ the most common highest neuron actvs\n","# mappings[90] gets the patch in image2 that is mapped to patch 90 in image1\n","mappings[90]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["117"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"6XwhFzkotF49","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646433986555,"user_tz":300,"elapsed":881,"user":{"displayName":"Michael Lan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13558259605338023275"}},"outputId":"fe913891-ec0a-4578-adb6-ff2a9f3974cf"},"source":["# Check which neurons these two mapped patches share\n","print(top_neurons_img1[90]) # The top 4 neurons that activate for patch 90 in image1\n","top_neurons_img2[mappings[90]] #use print() in notebook else only the last line is displayed"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[24, 286, 408, 416]\n"]},{"output_type":"execute_result","data":{"text/plain":["[82, 380, 408, 424]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["mappings_2[90]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"driTqLODHPOH","executionInfo":{"status":"ok","timestamp":1646434001510,"user_tz":300,"elapsed":145,"user":{"displayName":"Michael Lan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13558259605338023275"}},"outputId":"e6360125-0bcb-4427-f45e-eb3e9376ec57"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["103"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"Ae6-St6Hsf72"},"source":["# Feature viz the top 4 neurons in the patch in dog3 that maps to patch 90 in dog2\n","\n","for i in top_neurons_img2[mappings[90]]:\n","  obj = objectives.channel(\"mixed4d\", i)\n","  print('channel '+str(i))\n","  render.render_vis(googlenet, obj)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B5iKqOEbuu0h"},"source":["# Feature viz top neurons for both patch 61 and its mapped patch\n","\n","for i in top_neurons_img1[61]:  #nose\n","  obj = objectives.channel(\"mixed4d\", i)\n","  print('channel '+str(i))\n","  render.render_vis(googlenet, obj)\n","  \n","for i in top_neurons_img2[mappings[61]]:\n","  obj = objectives.channel(\"mixed4d\", i)\n","  print('channel '+str(i))\n","  render.render_vis(googlenet, obj)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kSNnuYb6vkWu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646432924372,"user_tz":300,"elapsed":1007,"user":{"displayName":"Michael Lan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13558259605338023275"}},"outputId":"edb9aa9a-f374-43d9-92a0-ff06310875fe"},"source":["# Get the intersection of the common top neurons b/w patch 61 and its mapped patch\n","# Use top 10 neurons\n","\n","top_10_img1_patch61 = output_top_neurons(\"mixed4d\", 'dog2.jpg', 10)[61]\n","top_10_img2_patch60 = output_top_neurons(\"mixed4d\", 'dog3.jpg', 10)[mappings[61]]\n","set(top_10_img1_patch61) - ( set(top_10_img1_patch61) - set(top_10_img2_patch60) )"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{49, 404, 460}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"C14cUjT3ZkHU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646433174539,"user_tz":300,"elapsed":1441,"user":{"displayName":"Michael Lan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13558259605338023275"}},"outputId":"b34d4b26-1efd-4ba6-fe36-23b647bb61fd"},"source":["# Instead of mapping a patch to one other patch, map it to the top N other patches\n","\n","def rank_patch_matches(img1_neurons, img2_neurons, num_patches):\n","    patch_mapping = {}  #patch in img1 : ranked list of patch tuples (patch in img2, # common neurons, set of neurons in common)\n","    for patch_1, neurons_1 in enumerate(img1_neurons): #a patch in img1, its ranking of neuron activations\n","        ranked_list = []\n","        for patch_2, neurons_2 in enumerate(img2_neurons):\n","            patch_2_tuple = [patch_2]\n","            common_elem = set(neurons_1).intersection(set(neurons_2))  #common neurons in both patches\n","            patch_2_tuple.append(len(common_elem))\n","            patch_2_tuple.append(common_elem)\n","            ranked_list.append(tuple(patch_2_tuple))\n","        ranked_list.sort(key = lambda x: x[1]) # sort tuples by 2nd element of tuple\n","        patch_mapping[patch_1] = ranked_list[-num_patches::]\n","    return patch_mapping\n","        \n","img1_neurons = output_top_neurons(\"mixed4d\", 'dog2.jpg', 4)\n","img2_neurons = output_top_neurons(\"mixed4d\", 'dog3.jpg', 4)\n","patch_mapping = rank_patch_matches(img1_neurons, img2_neurons, 10)\n","\n","patch_mapping[91]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(103, 1, {517}),\n"," (105, 1, {517}),\n"," (106, 1, {517}),\n"," (107, 1, {517}),\n"," (149, 1, {517}),\n"," (164, 1, {517}),\n"," (190, 1, {517}),\n"," (21, 2, {488, 517}),\n"," (34, 2, {488, 517}),\n"," (35, 2, {488, 517})]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"QL64cWzXY3lg"},"source":["# # Debug by finding out values of var inside fn\n","\n","# img1_neurons = output_top_neurons(\"mixed4d\", 'dog2.jpg', 4)\n","# img2_neurons = output_top_neurons(\"mixed4d\", 'dog3.jpg', 4)\n","# num_patches = 10\n","\n","# patch_mapping = {}  #patch in img1 : ranked list of patch tuples (patch in img2, # common neurons, set of neurons in common)\n","# for patch_1, neurons_1 in enumerate(img1_neurons): #a patch in img1, its ranking of neuron activations\n","#   # patch_ranking = {}  # patch in img2 : # common neurons w/ img1\n","#   # patch_ranking_2 = {}  # patch in img2 : set of neurons in common\n","#   ranked_list = []\n","#   for patch_2, neurons_2 in enumerate(img2_neurons):\n","#     patch_2_tuple = [patch_2]\n","#     common_elem = set(neurons_1).intersection(set(neurons_2))  #common neurons in both patches\n","#     # patch_ranking[patch_2] = len(common_elem)\n","#     # patch_ranking_2[patch_2] = common_elem\n","#     patch_2_tuple.append(len(common_elem))\n","#     patch_2_tuple.append(common_elem)\n","#     ranked_list.append(patch_2_tuple)\n","#   # sorted_patch_ranking = sorted(patch_ranking.items(), key=operator.itemgetter(1))\n","#   ranked_list.sort(key = lambda x: x[1]) \n","#   patch_mapping[patch_1] = ranked_list[-num_patches::]\n","\n","#   # patch_mapping_2[i] = patch_ranking_2\n","# # patch_mapping, patch_mapping_2\n","# patch_mapping[91]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G1NhdFpVkxi3"},"source":["#give weight to ranking; binary in/out and activation values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pJxYvfj9k7QA"},"source":["#function to label patch numbers, overlaying grid over image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PTnCDpIyk4Qf"},"source":["#run on 10 different images. Occlusion experiments."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHhdFnfyWmDo"},"source":["#gets aggregate stats such as 'avg # of common neurons b/w 2 mapped patches'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"9jAj_CXzmTxZ"}},{"cell_type":"code","source":[""],"metadata":{"id":"KnAZD6h4mUrj"},"execution_count":null,"outputs":[]}]}