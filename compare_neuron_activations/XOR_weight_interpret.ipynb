{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Use a NN to model XOR\n",
        "\n",
        "Study how individual motifs work to compose into larger circuits. Just like how studying AND gate composes into larger computer circuit, or how studying cells and particles enables understanding on a macroscopic level.\n",
        "\n",
        "Not for a research paper, but for personal understanding, which will help for future research papers.\n",
        "\n",
        "XOR is a geometric motif in latent space. Do other such motifs exist? Perhaps there is an analogous mathematical calculation to describe these motifs, and that generalizes these observations of this notebook."
      ],
      "metadata": {
        "id": "NgcSEMUjxL64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import torch\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os "
      ],
      "metadata": {
        "id": "gtIFVSFiemkY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Feedforward(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Feedforward, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size  = hidden_size\n",
        "        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)  # one hidden layer\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(self.hidden_size, 1)  #output layer w/o sigmoid\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        hidden = self.fc1(x)\n",
        "        relu = self.relu(hidden)\n",
        "        output = self.fc2(relu)\n",
        "        output = self.sigmoid(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "PQEESxRaeoLZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Feedforward(2, 2)\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "WxWLSjWReokH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor(np.array([[0,0], [0,1], [1,0], [1,1]]))\n",
        "y_train = torch.FloatTensor(np.array([0,1,1,0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4OXVdjofEiE",
        "outputId": "b534ea08-a930-4e27-f8bc-8291a4c7a61c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "epoch = 10000\n",
        "\n",
        "for epoch in range(epoch):\n",
        "    #sets the gradients to zero before we start backpropagation. \n",
        "    #This is a necessary step as PyTorch accumulates the gradients from the backward passes from the previous epochs.\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred.squeeze(), y_train)\n",
        "   \n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "vEfPg8mXevcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_pred = model(x_train)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T_uh9aPgbUs",
        "outputId": "3157c016-5f78-4722-f0b2-95550ae73116"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0526],\n",
              "        [0.9852],\n",
              "        [0.9830],\n",
              "        [0.0526]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Get activations\n"
      ],
      "metadata": {
        "id": "XhlF5lry1pIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_activations(input, layer_name):\n",
        "    activation = {}\n",
        "    def get_activation(name):\n",
        "        def hook(model, input, output):\n",
        "            activation[name] = output.detach()\n",
        "        return hook\n",
        "\n",
        "    for name_to_check, layer in model.named_modules():\n",
        "        if name_to_check == layer_name:\n",
        "            break\n",
        "    layer.register_forward_hook(get_activation(layer_name))\n",
        "    \n",
        "    output = model(input)\n",
        "\n",
        "    return activation.copy()  #else will return the same actvs of model"
      ],
      "metadata": {
        "id": "b0Q2cv-Gg2-b"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get previous last layer name\n",
        "named_layers = dict(model.named_modules())\n",
        "layers = list(named_layers.keys())\n",
        "\n",
        "# too many branches, so just get the converged branch points\n",
        "# '' is the entire model, so disregard it\n",
        "# layers = [x for x in layers if '.' not in x and x != '']  \n",
        "layers = [x for x in layers if x != '']  \n",
        "layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsCO7p5ghn6r",
        "outputId": "dc5ff46e-8f80-4343-a4b2-0171a3364335"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fc1', 'relu', 'fc2', 'sigmoid']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Compare different input activations\n",
        "\n",
        "Compare [0, 0] and [1, 0]"
      ],
      "metadata": {
        "id": "fe9CiE2IzobT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PcNkuzIjW_c",
        "outputId": "1eeafb4e-591d-4a9c-d92c-1832c425fd34"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_1 = x_train[0]\n",
        "out = model(input_1)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtUduynfh5WV",
        "outputId": "56e525e4-eed1-409f-f25c-d160153e006c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0526], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print(get_activations(input_1, layer_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgWQBapQhu_2",
        "outputId": "95662034-7ec6-4679-c87c-6eb7b8e83845"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': tensor([0.0526])}\n",
            "{'fc1': tensor([-3.6790e-05, -2.3193e-04])}\n",
            "{'relu': tensor([0., 0.])}\n",
            "{'fc2': tensor([-2.8915])}\n",
            "{'sigmoid': tensor([0.0526])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_2 = x_train[0] + torch.tensor([1,0])\n",
        "input_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B30L-rM0ZAB",
        "outputId": "79f2db11-92bd-48ca-f7a7-070edd27f2df"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print(get_activations(input_2, layer_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7uJ3bIo2hzL",
        "outputId": "d1e20889-e1e9-432f-8a86-541a1449b7ca"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1': tensor([ 2.2371, -2.2851])}\n",
            "{'relu': tensor([2.2371, 0.0000])}\n",
            "{'fc2': tensor([4.0572])}\n",
            "{'sigmoid': tensor([0.9830])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print( '[0,0]:', get_activations(input_1, layer_name), '[1,0]:', get_activations(input_2, layer_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaWcNLRT4faK",
        "outputId": "a933746b-fa4e-4a79-b84e-d1c2609b39d3"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0,0]: {'fc1': tensor([-3.6790e-05, -2.3193e-04])} [1,0]: {'fc1': tensor([ 2.2371, -2.2851])}\n",
            "[0,0]: {'relu': tensor([0., 0.])} [1,0]: {'relu': tensor([2.2371, 0.0000])}\n",
            "[0,0]: {'fc2': tensor([-2.8915])} [1,0]: {'fc2': tensor([4.0572])}\n",
            "[0,0]: {'sigmoid': tensor([0.0526])} [1,0]: {'sigmoid': tensor([0.9830])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    diff = get_activations(input_2, layer_name)[layer_name] - get_activations(input_1, layer_name)[layer_name]\n",
        "    print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKvQzZZojQd_",
        "outputId": "d0e7868c-b52f-4f0a-e729-f3de04c9fdc4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2.2371, -2.2849])\n",
            "tensor([2.2371, 0.0000])\n",
            "tensor([6.9488])\n",
            "tensor([0.9304])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Why does this input change cause this difference?\n",
        "\n",
        "Why are the activations different? Let's look at how each activation is calculated, and how the change in input causes the change in activation."
      ],
      "metadata": {
        "id": "HnO3gvvxjPt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EEVG3AxlamN",
        "outputId": "5f0f41d9-7291-4e19-eef7-d22ed486ff62"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Feedforward(\n",
              "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leeiDSBBi1hR",
        "outputId": "5efe3cd8-6947-429c-eacc-338ff1055cea"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 2.2371, -2.2374],\n",
            "        [-2.2849,  2.2847]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-3.6790e-05, -2.3193e-04], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[3.1062, 3.1020]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-2.8915], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prev_weights = model.fc1.weight.data\n",
        "prev_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PJMJ_Fcih8Y",
        "outputId": "2a5ab256-89e6-4389-a090-39fb98d8f82f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.2371, -2.2374],\n",
              "        [-2.2849,  2.2847]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in layers:\n",
        "    if isinstance(named_layers[layer], torch.nn.Linear):\n",
        "        print(layer, named_layers[layer].state_dict()['bias'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60Kz7M-IlDVk",
        "outputId": "448e9c7a-5d89-4553-cd60-d36c6f7b6803"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc1 tensor([-3.6790e-05, -2.3193e-04])\n",
            "fc2 tensor([-2.8915])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc1.weight.data * input_1 + named_layers['fc1'].state_dict()['bias']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWGz-fnHkihG",
        "outputId": "76548076-50cd-4ab2-c0a4-cc422fdff499"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.6790e-05, -2.3193e-04],\n",
              "        [-3.6790e-05, -2.3193e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc1.weight.data * input_2 + named_layers['fc1'].state_dict()['bias']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5SkMAulnMe0",
        "outputId": "f54a5551-6945-43b7-a596-a470b0ad36a9"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.2371e+00, -2.3193e-04],\n",
              "        [-2.2849e+00, -2.3193e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Break down each step of W * X + b"
      ],
      "metadata": {
        "id": "Pg8tBtwXtIk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc1.weight.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8FRJFM2tKdY",
        "outputId": "8542b8ad-69d2-437a-ce00-6ed55f4e7636"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.2371, -2.2374],\n",
              "        [-2.2849,  2.2847]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTuxxnF1tgoF",
        "outputId": "8f652abf-4828-41ca-dbb5-1d53c4c4800b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1000, 0.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WX_hadamard = torch.multiply(model.fc1.weight.data, input_2)\n",
        "WX_hadamard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0ZAOwGAsA2e",
        "outputId": "e4898519-4d29-410f-8aab-8d18595e425f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2237, -0.0000],\n",
              "        [-0.2285,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WX:\n",
        "\n",
        "[$w_{11}$ $w_{12}$]\n",
        "\n",
        "[$w_{21}$ $w_{22}$]\n",
        "\n",
        "w11 * (1) - w12 * 0 = w11\n",
        "\n",
        "w21 * (1) + w22 * 0 = w21\n",
        "\n",
        "Thus, when you change the input from [0, 0] to [1, 0], you are changing WX from [0, 0] to [w11, w21]. And we know that [1, 0] is supposed to be 1.\n",
        "\n",
        "But we also need [1, 1] to be 0, so it's not as simple as \"make it so the neuron outputs are bigger\". "
      ],
      "metadata": {
        "id": "MFSOGb3QtoW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix multiplication is unit conversion. Row of W multiplies by column X"
      ],
      "metadata": {
        "id": "BqRA-AOTq_DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_3 = torch.FloatTensor(np.array([1,1]))\n",
        "input_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOC5MW_xvZgd",
        "outputId": "2d3c6671-e697-4715-fc2d-51d7b6d7f774"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    print(get_activations(input_3, layer_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pl5CPs0vnTY",
        "outputId": "191efa87-e94c-41a9-bee6-2fd3bce8866e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fc1': tensor([-0.0003, -0.0004])}\n",
            "{'relu': tensor([0., 0.])}\n",
            "{'fc2': tensor([-2.8915])}\n",
            "{'sigmoid': tensor([0.0526])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_name in layers:\n",
        "    diff = get_activations(input_3, layer_name)[layer_name] - get_activations(input_1, layer_name)[layer_name]\n",
        "    print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAYgAl6ev_aw",
        "outputId": "78d950d2-a09b-4a51-c672-7ae9329650b8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0002, -0.0002])\n",
            "tensor([0., 0.])\n",
            "tensor([0.])\n",
            "tensor([0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[0, 0] and [1, 1] have the SAME neuron outputs after fc1. Let's look at the weights of fc1 again to see why that's the case."
      ],
      "metadata": {
        "id": "8jhHweq9wRsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc1.weight.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-HCBi1EwZBr",
        "outputId": "7a511ca2-e01f-4906-cd78-18ed72d57500"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.2371, -2.2374],\n",
              "        [-2.2849,  2.2847]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WX_hadamard = torch.multiply(model.fc1.weight.data, input_3)\n",
        "WX_hadamard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8_u4oI3wnuv",
        "outputId": "8d522220-9418-4a11-f87c-e4f65eea57b7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.2371, -2.2374],\n",
              "        [-2.2849,  2.2847]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first element of WX is: 2.2371 -2.2374 = -0.002 \n",
        "\n",
        "The second element is also close to 0.\n",
        "\n",
        "So the weights were learned to make sure w11 - w12 was close to 0, as ReLU would turn that into 0.\n",
        "\n",
        "Then in fc2 (output node), the bias is negative so that sigmoid makes it less than 0. But for [0,1] and [1,0], \n",
        "\n",
        "For multiple training instances, does it do this every time? There may be multiple ways for an ANN circuit to calculate XOR.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WqmNyaNTwi04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Gradual input modification \n",
        "\n",
        "Now slightly modify the input and see what happens to each layer!\n",
        "\n",
        "Try different modification levels. As you gradually change it, how do the weights change?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Use:\n",
        "torch.tensor([0.0, 0.0]) instead of torch.tensor([0, 0])\n",
        "\n",
        "https://stackoverflow.com/questions/60440292/runtimeerror-expected-scalar-type-long-but-found-float"
      ],
      "metadata": {
        "id": "aARB9Xwa0V8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name = 'fc1'\n",
        "# step_incr = [round(x * 0.1, 1) for x in range(0, 10)]\n",
        "old_input = torch.tensor([0.0, 0.0])\n",
        "new_input = torch.tensor([0.0, 0.0])\n",
        "# for i in step_incr:\n",
        "for i in range(0, 10):\n",
        "    old_input = new_input.clone()\n",
        "    new_input = old_input + torch.tensor([0.1, 0])\n",
        "    # new_input = torch.tensor([i, 0])\n",
        "    print(0.1 * i)\n",
        "    diff = get_activations(new_input, layer_name)[layer_name] - get_activations(old_input, layer_name)[layer_name]\n",
        "    print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIFRwlqQ0aNL",
        "outputId": "7928154f-cf27-425b-ebfb-41ca01be0286"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "tensor([ 0.2237, -0.2285])\n",
            "0.1\n",
            "tensor([ 0.2237, -0.2285])\n",
            "0.2\n",
            "tensor([ 0.2237, -0.2285])\n",
            "0.30000000000000004\n",
            "tensor([ 0.2237, -0.2285])\n",
            "0.4\n",
            "tensor([ 0.2237, -0.2285])\n",
            "0.5\n",
            "tensor([ 0.2237, -0.2285])\n",
            "0.6000000000000001\n",
            "tensor([ 0.2237, -0.2285])\n",
            "0.7000000000000001\n",
            "tensor([ 0.2237, -0.2285])\n",
            "0.8\n",
            "tensor([ 0.2237, -0.2285])\n",
            "0.9\n",
            "tensor([ 0.2237, -0.2285])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's the same increment every time, since WX+b is linear.\n",
        "\n",
        "Now instead of comparing with previous, compare it with original"
      ],
      "metadata": {
        "id": "GH8CmR_h6rUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name = 'fc1'\n",
        "old_input = torch.tensor([0.0, 0.0])\n",
        "new_input = torch.tensor([0.0, 0.0])\n",
        "for i in range(0, 10):\n",
        "    old_input = new_input.clone()\n",
        "    new_input = old_input + torch.tensor([0.1, 0])\n",
        "    print([0.1 * i, 0])\n",
        "    actv_new = get_activations(new_input, layer_name)[layer_name]\n",
        "    actv_orig = get_activations(torch.tensor([0.0, 0.0]), layer_name)[layer_name]\n",
        "    diff = actv_new - actv_orig\n",
        "    print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIKtVXtp6q05",
        "outputId": "d6d64016-5fc3-4126-de3f-9f139458be9a"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0]\n",
            "tensor([ 0.2237, -0.2285])\n",
            "[0.1, 0]\n",
            "tensor([ 0.4474, -0.4570])\n",
            "[0.2, 0]\n",
            "tensor([ 0.6711, -0.6855])\n",
            "[0.30000000000000004, 0]\n",
            "tensor([ 0.8949, -0.9140])\n",
            "[0.4, 0]\n",
            "tensor([ 1.1186, -1.1424])\n",
            "[0.5, 0]\n",
            "tensor([ 1.3423, -1.3709])\n",
            "[0.6000000000000001, 0]\n",
            "tensor([ 1.5660, -1.5994])\n",
            "[0.7000000000000001, 0]\n",
            "tensor([ 1.7897, -1.8279])\n",
            "[0.8, 0]\n",
            "tensor([ 2.0134, -2.0564])\n",
            "[0.9, 0]\n",
            "tensor([ 2.2371, -2.2849])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before, we saw that going from [0, 0] to [1, 0] makes WX go from around [0, 0] to [w11, w21]. We see an increase in w11 as x1 gets larger. Similarly, w21's magnitude also gets larger as x1 gets larger.\n",
        "\n",
        "Now how is [w11, w21] used in fc2? It might not matter because ReLU after fc1 turns [w11, w21] to [0, 0] is they are negative. If [fc1_1 and fc1_2] are close to 0, since the bias is negative, the relu will make them [0,0]. So the [0,1] and [1,0] have to ensure that "
      ],
      "metadata": {
        "id": "8HDWZsmw65rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc2.weight.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUtqEKAg_OyA",
        "outputId": "bea82808-a985-43ce-e6f1-ba32d37367f8"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.1062, 3.1020]])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LalPeA0X_SiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Let's gradually change along the diagonal from [0,0] to [1,1]"
      ],
      "metadata": {
        "id": "-Qa-h8WWAWEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name = 'fc1'\n",
        "old_input = torch.tensor([0.0, 0.0])\n",
        "new_input = torch.tensor([0.0, 0.0])\n",
        "for i in range(0, 10):\n",
        "    old_input = new_input.clone()\n",
        "    new_input = old_input + torch.tensor([0.1, 0.1])\n",
        "    print([0.1 * i, 0.1 * i])\n",
        "    actv_new = get_activations(new_input, layer_name)[layer_name]\n",
        "    actv_orig = get_activations(torch.tensor([0.0, 0.0]), layer_name)[layer_name]\n",
        "    diff = actv_new - actv_orig\n",
        "    print(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSgfv6EIAbW1",
        "outputId": "c478700a-b081-49e4-f440-63c545ef2713"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.0]\n",
            "tensor([-2.4229e-05, -2.0996e-05])\n",
            "[0.1, 0.1]\n",
            "tensor([-4.8459e-05, -4.1991e-05])\n",
            "[0.2, 0.2]\n",
            "tensor([-7.2658e-05, -6.3002e-05])\n",
            "[0.30000000000000004, 0.30000000000000004]\n",
            "tensor([-9.6917e-05, -8.3983e-05])\n",
            "[0.4, 0.4]\n",
            "tensor([-0.0001, -0.0001])\n",
            "[0.5, 0.5]\n",
            "tensor([-0.0001, -0.0001])\n",
            "[0.6000000000000001, 0.6000000000000001]\n",
            "tensor([-0.0002, -0.0001])\n",
            "[0.7000000000000001, 0.7000000000000001]\n",
            "tensor([-0.0002, -0.0002])\n",
            "[0.8, 0.8]\n",
            "tensor([-0.0002, -0.0002])\n",
            "[0.9, 0.9]\n",
            "tensor([-0.0002, -0.0002])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Along this diagonal, [fc1_1 and fc1_2] always stay negative and close to 0, unlike going from [0, 0] to [1, 0], where fc1_1 increases.\n",
        "\n",
        "This is because fc1_1 = w11 + w12, and w11 ~= -w12, so whenever the coefficients x1 and x2 are close in value, so will x1 * w11 and x2 * w12. "
      ],
      "metadata": {
        "id": "nj4UIgmhAgWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Conditions to allow NN to model XOR: (one possible state)\n",
        "\n",
        "- the weights were learned to make sure w1 - w2 was close to 0 (ie. w11 ~= -w12)\n",
        "- fc2's bias should be negative to ensure WX after fc2, if 0, will make it neg, thus making sigmoid make WX+b be close to 0\n",
        "\n",
        "Any NN with the architecture above whose weights satisfy these conditions will model XOR.\n",
        "\n",
        "Thus, we can possibly analogously match NNs satisfying these same conditions by their motifs. "
      ],
      "metadata": {
        "id": "e3YhHgKt480T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Change of basis, human-like interpretation (approx.):\n",
        "\n",
        "For fc1, the first row of WX measures how similar $x_1$ and $x_2$ are. The second row does the same."
      ],
      "metadata": {
        "id": "lm-jq8-97m0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Now these NN motifs are how weights are related to one another. For instance, w11 ~= -w12. Any sub-network satisfying these constraints is \"that motif\". Finding these motifs across a large NN means finding patterns that satisfy each condition. Each condition is stricter, making a more specific and larger pattern query, so adding more conditions means less matches.\n",
        "\n",
        "These are not 'exact' patterns, but analogous, since weights are RELATIVE to one another. For instance, w11 > w12, not requiring w11 to exactly have some value (though it may)."
      ],
      "metadata": {
        "id": "TssTqwl6Bk71"
      }
    }
  ]
}